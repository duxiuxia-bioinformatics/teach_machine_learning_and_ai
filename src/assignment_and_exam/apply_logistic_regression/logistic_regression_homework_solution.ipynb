{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9639656b",
   "metadata": {},
   "source": [
    "# Logistic Regression in Bioinformatics — Homework Solution Notebook\n",
    "\n",
    "This notebook provides a **complete worked solution** (conceptual + coding) for the Logistic Regression homework.\n",
    "\n",
    "**Topics covered**\n",
    "- log-odds, odds ratios, probability computation\n",
    "- sklearn logistic regression + ROC/PR\n",
    "- class imbalance and thresholding\n",
    "- confounding and sign flips (simulation)\n",
    "- L1/L2 regularization\n",
    "- statsmodels inference (SE, z, p-values, CI)\n",
    "- nonlinear relationships and feature engineering\n",
    "\n",
    "> Instructor note: You can hide solution cells or convert this into a student version by removing the answer text/outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ada29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff483da",
   "metadata": {},
   "source": [
    "## Problem 1 — Conceptual Foundations (Answer Key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5021e6",
   "metadata": {},
   "source": [
    "### (a) Why logistic regression over linear regression for binary outcomes?\n",
    "\n",
    "- Linear regression can predict values **< 0 or > 1**, which are invalid probabilities.\n",
    "- Logistic regression models the probability via a **sigmoid** so predictions are in \\([0,1]\\).\n",
    "- Logistic regression assumes the **log-odds** are linear in predictors, which is more appropriate for Bernoulli outcomes.\n",
    "- Error distribution assumptions differ: linear regression assumes Gaussian errors; logistic regression uses a Bernoulli likelihood.\n",
    "\n",
    "### (b) Meaning of \\(\\log(\\frac{p}{1-p})\\)\n",
    "\n",
    "- \\(\\frac{p}{1-p}\\) is the **odds** of disease (probability of disease divided by probability of no disease).\n",
    "- The log transforms odds to a real-valued scale (log-odds) where additive effects are natural.\n",
    "\n",
    "### (c) If \\(\\beta_1 = 0.7\\), interpret\n",
    "1) **Log-odds:** increasing the predictor by 1 increases log-odds by 0.7.  \n",
    "2) **Odds ratio:** \\(e^{0.7} \\approx 2.01\\). Odds multiply by about **2×** for each +1 increase.  \n",
    "3) **Biological meaning:** a one-unit increase in the feature is associated with roughly **doubling** the odds of disease (holding other variables constant).\n",
    "\n",
    "### (d) Why diminishing returns near 0 and 1?\n",
    "\n",
    "The sigmoid \\(p = \\frac{1}{1+e^{-z}}\\) saturates near 0 and 1. Equal changes in log-odds \\(z\\) produce smaller probability changes when \\(p\\) is already close to 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick numeric check for Problem 1(c)\n",
    "beta1 = 0.7\n",
    "np.exp(beta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df3ff6",
   "metadata": {},
   "source": [
    "## Problem 2 — Manual Computation (Answer Key)\n",
    "Model:  \\(\\log(\\frac{p}{1-p}) = -2 + 0.8\\cdot GeneA\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b69345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+math.exp(-z))\n",
    "\n",
    "# (a) GeneA=0\n",
    "z0 = -2 + 0.8*0\n",
    "p0 = sigmoid(z0)\n",
    "\n",
    "# (b) GeneA=3\n",
    "z3 = -2 + 0.8*3\n",
    "p3 = sigmoid(z3)\n",
    "\n",
    "# (c) OR for one-unit increase\n",
    "OR = math.exp(0.8)\n",
    "\n",
    "p0, p3, OR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321721d0",
   "metadata": {},
   "source": [
    "### Answers\n",
    "- (a) GeneA = 0: logit = \\(-2\\) → \\(p \\approx 0.119\\)\n",
    "- (b) GeneA = 3: logit = \\(-2 + 2.4 = 0.4\\) → \\(p \\approx 0.599\\)\n",
    "- (c) Odds ratio for +1 GeneA: \\(e^{0.8} \\approx 2.23\\)\n",
    "- (d) Interpretation: each +1 in GeneA multiplies the odds of disease by ~2.23 (holding other variables fixed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27564cc",
   "metadata": {},
   "source": [
    "## Problem 3 — Tiny Dataset by Hand (Answer Key)\n",
    "Dataset increases GeneX as disease becomes more likely.\n",
    "\n",
    "**(a)** Sigmoid should increase with GeneX, crossing ~0.5 around the transition region (between 3 and 4).  \n",
    "**(b)** Linear regression is inappropriate because predictions could go outside [0,1] and the error model is wrong for Bernoulli outcomes.  \n",
    "**(c)** The coefficient should be **positive** because higher GeneX corresponds to higher probability of disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a0ebb1",
   "metadata": {},
   "source": [
    "## Problem 4 — Python Implementation (sklearn) (Solution)\n",
    "We generate an imbalanced dataset (80/20), fit logistic regression, and evaluate with ROC and PR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "X, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=20,\n",
    "    n_informative=5,\n",
    "    n_redundant=2,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    weights=[0.8, 0.2],  # imbalance: 80% controls, 20% cases\n",
    "    class_sep=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Pipeline: standardize then logistic regression\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# (b) coefficients + intercept\n",
    "coef = clf.named_steps[\"lr\"].coef_.ravel()\n",
    "intercept = clf.named_steps[\"lr\"].intercept_[0]\n",
    "\n",
    "coef[:8], intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a874a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities for first 5 samples in test set\n",
    "proba_test = clf.predict_proba(X_test)[:, 1]\n",
    "proba_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb27646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) ROC and AUC\n",
    "fpr, tpr, roc_thresh = roc_curve(y_test, proba_test)\n",
    "auc = roc_auc_score(y_test, proba_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"ROC Curve (AUC = {auc:.3f})\")\n",
    "plt.show()\n",
    "\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0057ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d) Precision-Recall curve and Average Precision\n",
    "prec, rec, pr_thresh = precision_recall_curve(y_test, proba_test)\n",
    "ap = average_precision_score(y_test, proba_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rec, prec)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(f\"Precision–Recall Curve (AP = {ap:.3f})\")\n",
    "plt.show()\n",
    "\n",
    "ap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30d998",
   "metadata": {},
   "source": [
    "### (e) Why ROC can look “good” while PR looks “bad” under imbalance?\n",
    "\n",
    "- ROC uses **FPR**, which divides by the number of negatives (often huge). With many negatives, a model can have small FPR even with many false positives.\n",
    "- PR focuses on the **positive class**: precision penalizes false positives directly.\n",
    "- In rare-disease settings, PR/AP often gives a more realistic picture of clinical usefulness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8823b7b9",
   "metadata": {},
   "source": [
    "## Problem 5 — Odds Ratio Interpretation in Genomics (Answer Key)\n",
    "Given a SNP genotype coded 0/1/2 with \\(\\beta=-1.2\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = -1.2\n",
    "OR_1 = np.exp(beta)         # per +1 genotype\n",
    "OR_2 = np.exp(beta*2)       # from 0 -> 2\n",
    "OR_1, OR_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3afbfc",
   "metadata": {},
   "source": [
    "### Answers\n",
    "- (a) Odds ratio for +1 genotype: \\(e^{-1.2} \\approx 0.301\\)\n",
    "- (b) Because OR < 1, the SNP is **protective** (higher genotype count reduces odds).\n",
    "- (c) From genotype 0 → 2: odds multiply by \\(e^{-2.4} \\approx 0.091\\). That’s ~**90% lower odds** compared to genotype 0 (holding other variables constant)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e8a99",
   "metadata": {},
   "source": [
    "## Problem 6 — Confounding (Answer Key + Simulation)\n",
    "\n",
    "**Key idea:** If GeneA correlates with Age, and Age affects disease, then a model omitting Age can attribute Age’s effect to GeneA.\n",
    "\n",
    "- (a) Confounding can inflate/deflate GeneA’s coefficient.\n",
    "- (b) **Yes, sign flips can occur** when GeneA is positively correlated with Age but has a negative direct effect (or vice versa).\n",
    "- (c) In genomics, **population stratification** is a confounding analog: ancestry correlates with genotype and disease risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c4d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation demonstrating potential sign flip\n",
    "\n",
    "rng = np.random.default_rng(1)\n",
    "n = 2000\n",
    "\n",
    "# Age influences disease positively\n",
    "age = rng.normal(50, 10, size=n)\n",
    "\n",
    "# GeneA correlated with age (confounding): older individuals tend to have higher GeneA\n",
    "geneA = 0.08*age + rng.normal(0, 1, size=n)\n",
    "\n",
    "# True direct effect: GeneA is mildly protective (negative), age increases risk (positive)\n",
    "# logit = b0 + b_age*age + b_gene*geneA\n",
    "b0, b_age, b_gene = -8.0, 0.12, -0.8\n",
    "\n",
    "logit = b0 + b_age*age + b_gene*geneA\n",
    "p = 1/(1+np.exp(-logit))\n",
    "y_sim = rng.binomial(1, p, size=n)\n",
    "\n",
    "# Fit two models with statsmodels for interpretability\n",
    "df = pd.DataFrame({\"y\": y_sim, \"GeneA\": geneA, \"Age\": age})\n",
    "\n",
    "X1 = sm.add_constant(df[[\"GeneA\"]])\n",
    "m1 = sm.Logit(df[\"y\"], X1).fit(disp=False)\n",
    "\n",
    "X2 = sm.add_constant(df[[\"GeneA\", \"Age\"]])\n",
    "m2 = sm.Logit(df[\"y\"], X2).fit(disp=False)\n",
    "\n",
    "m1.params, m2.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c331386",
   "metadata": {},
   "source": [
    "If you see GeneA’s coefficient change substantially (or flip sign) after adding Age, that’s the hallmark of confounding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b32a6",
   "metadata": {},
   "source": [
    "## Problem 7 — Regularization (L1 vs L2 vs None) (Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare penalties on the same train/test split\n",
    "models = {\n",
    "    \"none (approx)\": LogisticRegression(max_iter=5000, penalty=\"l2\", C=1e6, solver=\"lbfgs\"),\n",
    "    \"L2\": LogisticRegression(max_iter=5000, penalty=\"l2\", C=1.0, solver=\"lbfgs\"),\n",
    "    \"L1\": LogisticRegression(max_iter=5000, penalty=\"l1\", C=1.0, solver=\"liblinear\"),\n",
    "}\n",
    "\n",
    "coef_table = []\n",
    "for name, lr in models.items():\n",
    "    pipe = Pipeline([(\"scaler\", StandardScaler()), (\"lr\", lr)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    coefs = pipe.named_steps[\"lr\"].coef_.ravel()\n",
    "    coef_table.append({\n",
    "        \"model\": name,\n",
    "        \"num_near_zero(|coef|<1e-3)\": int(np.sum(np.abs(coefs) < 1e-3)),\n",
    "        \"coef_L1_norm\": float(np.sum(np.abs(coefs))),\n",
    "        \"coef_L2_norm\": float(np.sqrt(np.sum(coefs**2))),\n",
    "        \"test_AUC\": float(roc_auc_score(y_test, pipe.predict_proba(X_test)[:,1])),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(coef_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e326f",
   "metadata": {},
   "source": [
    "### Answers\n",
    "- (a) Regularization shrinks coefficients; L1 often shrinks many to **exactly 0**.\n",
    "- (b) **L1** performs feature selection (sparse coefficients).\n",
    "- (c) Omics data often has \\(p \\gg n\\) (many features, few samples). Regularization reduces overfitting and improves generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd17d1f",
   "metadata": {},
   "source": [
    "## Problem 8 — Thresholding and Confusion Matrices (Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e4877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.5, 0.3, 0.1]\n",
    "\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    y_pred = (proba_test >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp+fn) else np.nan  # recall\n",
    "    specificity = tn / (tn + fp) if (tn+fp) else np.nan\n",
    "    precision = tp / (tp + fp) if (tp+fp) else np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"threshold\": t,\n",
    "        \"TN\": tn, \"FP\": fp, \"FN\": fn, \"TP\": tp,\n",
    "        \"sensitivity(recall)\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70588a01",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "- Lowering the threshold generally **increases sensitivity (recall)** but decreases specificity and often precision.\n",
    "- (c) For **cancer screening**, you often prefer higher sensitivity (fewer missed cases), so a lower threshold (e.g., 0.3 or 0.1) may be chosen, with follow-up confirmatory testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d1b25",
   "metadata": {},
   "source": [
    "## Problem 9 — Statistical Inference (statsmodels) (Solution + Answer Key)\n",
    "We fit logistic regression and extract SE, z, p-values, and confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a77c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit statsmodels logistic regression on the synthetic dataset\n",
    "# (using standardized predictors for stability/interpretability)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_s)\n",
    "X_test_sm = sm.add_constant(X_test_s)\n",
    "\n",
    "sm_model = sm.Logit(y_train, X_train_sm).fit(disp=False)\n",
    "sm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bee5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract inference quantities\n",
    "params = sm_model.params\n",
    "se = sm_model.bse\n",
    "z = params / se\n",
    "pvals = sm_model.pvalues\n",
    "ci = sm_model.conf_int()\n",
    "ci.columns = [\"CI_low\", \"CI_high\"]\n",
    "\n",
    "out = pd.DataFrame({\n",
    "    \"coef\": params,\n",
    "    \"std_err\": se,\n",
    "    \"z\": z,\n",
    "    \"p_value\": pvals,\n",
    "    \"CI_low\": ci[\"CI_low\"],\n",
    "    \"CI_high\": ci[\"CI_high\"],\n",
    "})\n",
    "out.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544c1ec",
   "metadata": {},
   "source": [
    "### Answer Key Notes\n",
    "- (c) Many logistic regression p-values are computed using the **Wald test**:\n",
    "  \\[\n",
    "  z = \\frac{\\hat\\beta}{SE(\\hat\\beta)}\n",
    "  \\]\n",
    "  and a two-sided p-value from the standard normal distribution.\n",
    "- (d) “Statistically significant but small effect size” can happen with larger samples or low noise; it means the association is reliable but may not be clinically meaningful by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9446792b",
   "metadata": {},
   "source": [
    "## Problem 10 — Nonlinearity (Answer Key + Demo)\n",
    "If the true relationship is nonlinear, logistic regression with only linear terms can underfit.\n",
    "We can add polynomial terms or interactions to capture curvature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b36aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple nonlinear 1D example: disease risk increases for very low or very high x (U-shaped)\n",
    "rng = np.random.default_rng(2)\n",
    "n = 800\n",
    "x = rng.uniform(-3, 3, size=n)\n",
    "\n",
    "# True probability depends on x^2 (nonlinear)\n",
    "logit_true = -2 + 1.2*(x**2)  # U-shaped risk\n",
    "p_true = 1/(1+np.exp(-logit_true))\n",
    "y_nl = rng.binomial(1, p_true)\n",
    "\n",
    "# Fit linear logistic regression (misspecified)\n",
    "X_lin = x.reshape(-1,1)\n",
    "X_train_nl, X_test_nl, y_train_nl, y_test_nl = train_test_split(X_lin, y_nl, test_size=0.3, random_state=0, stratify=y_nl)\n",
    "\n",
    "lin_lr = Pipeline([(\"scaler\", StandardScaler()), (\"lr\", LogisticRegression(max_iter=2000))])\n",
    "lin_lr.fit(X_train_nl, y_train_nl)\n",
    "proba_lin = lin_lr.predict_proba(X_test_nl)[:,1]\n",
    "auc_lin = roc_auc_score(y_test_nl, proba_lin)\n",
    "\n",
    "# Fit logistic regression with polynomial feature x^2\n",
    "X_poly = np.column_stack([x, x**2])\n",
    "Xp_train, Xp_test, yp_train, yp_test = train_test_split(X_poly, y_nl, test_size=0.3, random_state=0, stratify=y_nl)\n",
    "\n",
    "poly_lr = Pipeline([(\"scaler\", StandardScaler()), (\"lr\", LogisticRegression(max_iter=2000))])\n",
    "poly_lr.fit(Xp_train, yp_train)\n",
    "proba_poly = poly_lr.predict_proba(Xp_test)[:,1]\n",
    "auc_poly = roc_auc_score(yp_test, proba_poly)\n",
    "\n",
    "auc_lin, auc_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad40fa89",
   "metadata": {},
   "source": [
    "### Answers\n",
    "- (a) If true log-odds are nonlinear, a linear logit model may underfit and give biased probability estimates.\n",
    "- (b) Fixes: add polynomial terms, splines, interactions, or switch to nonlinear models.\n",
    "- (c) Decision trees can outperform logistic regression when relationships include strong nonlinearities and interactions, or when rules/thresholds dominate (but they can overfit without pruning/regularization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73120f9b",
   "metadata": {},
   "source": [
    "## Bonus — Rare Disease (Answer Key)\n",
    "\n",
    "- (a) Accuracy is not a good metric at 1% prevalence (a model that predicts all negatives gets 99% accuracy).\n",
    "- (b) Prefer PR/Average Precision, Recall at fixed Precision, or cost-sensitive metrics; also consider ROC but interpret carefully.\n",
    "- (c) Training adjustments: class weights, focal loss (in other models), undersampling/oversampling (SMOTE), and careful threshold selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
